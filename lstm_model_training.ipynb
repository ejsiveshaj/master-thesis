{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required Python libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import lstm_model_modules as lmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file_path = 'train_data.csv'\n",
    "# Extracting only the demand column \n",
    "demand_column = lmm.get_demand_column(training_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the above numpy array into train (80%) and validation sets:\n",
    "train_size = int(len(demand_column) * 0.8)\n",
    "train_set = demand_column[:train_size]\n",
    "val_set = demand_column[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the scaler value\n",
    "scaler = lmm.return_scaler(training_file_path)\n",
    "\n",
    "# Scaling the train and validation sets\n",
    "train_scaled = train_set * scaler \n",
    "val_scaled = val_set * scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the train and validation sets, using a specific lookback range\n",
    "look_back = 336 # since our data is weekly periodic\n",
    "X_train, Y_train = lmm.create_dataset(train_scaled, look_back)\n",
    "X_val, Y_val = lmm.create_dataset(val_scaled, look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the LSTM model's structure and compiling it\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=64, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False))\n",
    "# model.add(LSTM(units=32))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Defining early stopping criteria\n",
    "es = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model with early stopping\n",
    "history = model.fit(X_train, Y_train, epochs=100, batch_size=16, validation_data=(X_val, Y_val), callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting and comparing the training and validation loss\n",
    "plt.plot(history.history['loss'], label='Training loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the best model\n",
    "model.save(\"model_using_only_demand_col.h5\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px"
      ],
      "metadata": {
        "id": "IDjMqYu2NLcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAsC-0maNCZp"
      },
      "outputs": [],
      "source": [
        "def cosine_distribution_updated(amplitude, bias, nr_data_points, randomness_level):\n",
        "  \"\"\"\n",
        "  Generates a cosine distribution with given  amplitude, bias, required number of data points \n",
        "  and randomness_level. It returns the respective numpy array of generated values.\n",
        "  \"\"\"\n",
        "\n",
        "  frequency = 0.5 # An arbitrary value for the frequency (however it doesn't significantly affect the generated values)  \n",
        "  nr_cosine_periods = 24 / nr_data_points # Calculating the number of cosine periods needed so that the data points\n",
        "  # having a cosine shape, represent 1 entire cosine period.\n",
        "\n",
        "  # Generating 24 evenly spaced x values within the interval (0, number of cosine periods)  \n",
        "  x = np.linspace(0, nr_cosine_periods * 2 * np.pi / frequency, 24) \n",
        "\n",
        "  # Calculating the respective y values using the cosine distribution formula\n",
        "  y = amplitude * np.cos(frequency * x) + bias\n",
        "\n",
        "  # Calculating the noise factor using the randomness_level argument, which takes values between 0 and 4. \n",
        "  # The greater its value, the higher the level of randomness.\n",
        "  noise_factor = amplitude / (5 - randomness_level) if randomness_level != 0 else 0\n",
        "\n",
        "  # Adding the noise effect\n",
        "  y += np.random.normal(0, 0.1, 24) * noise_factor\n",
        "\n",
        "  # Returning the np array of y\n",
        "  return y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_peak_updated(peak_val, respective_h, diff_between_max_min, randomness_level, peak_randomness):\n",
        "  \"\"\"\n",
        "    Generates a normal distribution containing 24 data points, with given mean ('respective_h') and\n",
        "    then transforms it so that it represents the daily demand, where 'peak_val' is its\n",
        "    peak value, 'respective_h' is the respective peak's hour and 'diff_between_max_min' is the \n",
        "    difference between the max and min demand values during the time interval that we are interested. \n",
        "    It returns the respective numpy array containing the daily demand values for each hour.  \n",
        "  \"\"\"\n",
        "\n",
        "  mean = respective_h\n",
        "  std = 0.2 * mean\n",
        "\n",
        "  # Numpy array containing hours from 0 to 23.\n",
        "  x = np.arange(24)\n",
        "  \n",
        "  # Gaussian distribution equation which produces probability values.\n",
        "  # x = mean value, corresponds with the highest probability value\n",
        "  y = 1/(std * np.sqrt(2 * np.pi)) * np.exp(-1/2 * ((x - mean) / std) ** 2)\n",
        "\n",
        "  # Probability values are between 0 and 1, but we need them to represent demand values,\n",
        "  # where the difference between the max and min values is 'diff_between_max_min'. \n",
        "  y *= (diff_between_max_min / np.max(y))\n",
        "\n",
        "  # If the data distribution still doesn't include the peak value, we transform it again,\n",
        "  # by shifting the values vertically till we make that possible.\n",
        "  # Before doing that, we make the peak value random based on the peak_randomness value.\n",
        "  peak_noise_factor =  peak_val / (5 - peak_randomness) if peak_randomness != 0 else 0\n",
        "  peak_val += np.random.uniform(0, 0.2) * peak_noise_factor \n",
        "  y += (peak_val - np.max(y)) \n",
        "\n",
        "  # Adding general random noise.\n",
        "  noise_factor = diff_between_max_min / (5 - randomness_level) if randomness_level != 0 else 0\n",
        "  y += np.random.normal(0, 0.1, 24) * noise_factor\n",
        "\n",
        "  return y"
      ],
      "metadata": {
        "id": "mP9pQAz-NMnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_daily_demand_updated(cos_first_val, cos_nr_points, first_peak_val, \n",
        "                                  first_peak_resp_h, first_peak_diff_max_min,\n",
        "                                  second_peak_val, second_peak_resp_h, \n",
        "                                  second_peak_diff_max_min, randomness_level,\n",
        "                                  peak_randomness):\n",
        "  \"\"\"\n",
        "    Generates the daily demand for car sharing service in a german city. It uses the helper functions\n",
        "    defined above and returns a numpy array containing the hourly demand values (24 values) for a day.\n",
        "  \"\"\"\n",
        "\n",
        "  # Calculating the cosine amplitude and bias values based on the demand value at 0 hour, which usually represents\n",
        "  # both the maximum cosine value and also the difference between min and max values of the cosine distribution. \n",
        "  amplitude = cos_first_val / 2    \n",
        "  bias = cos_first_val / 2 + 10\n",
        "  # Generating the demand for the first 'cos_nr_points' hours.          \n",
        "  y1 = cosine_distribution_updated(amplitude, bias, cos_nr_points, randomness_level)\n",
        "\n",
        "  # Generating the normal distribution containing the first demand peak.\n",
        "  y2 = generate_peak_updated(first_peak_val, first_peak_resp_h, first_peak_diff_max_min, randomness_level, peak_randomness)\n",
        "\n",
        "  # Generating the normal distribution containing the second demand peak.\n",
        "  y3 = generate_peak_updated(second_peak_val, second_peak_resp_h, second_peak_diff_max_min, randomness_level, peak_randomness) \n",
        "\n",
        "  # Definining 3 \"window\" lists containing weight values, which will multiply the daily demand represented by\n",
        "  # the cosine and 2 normal distributions.\n",
        "  if (cos_nr_points < 8):\n",
        "    window_1 = np.array([1] * (cos_nr_points - 1) + [1.4] + [0] * (24 - cos_nr_points))\n",
        "  else:  \n",
        "    window_1 = np.array([1, 0.9] + [1] * 6 + [0] * 16)\n",
        "  window_2 = np.array([0] * cos_nr_points + [1] * (24 - cos_nr_points - 10) + [1.1, 1.4] + [0] * 8)\n",
        "  window_3 = np.array([0] * 16 + [1] * 6 + [1, 0.8])\n",
        "  \n",
        "  # Multiplying each of the values that we got from each distribution with the respective weights.\n",
        "  result_1 = y1 * window_1\n",
        "  result_2 = y2 * window_2\n",
        "  result_3 = y3 * window_3\n",
        "\n",
        "  # Adding the values of 3 lists in order to get the entire daily demand.\n",
        "  final_result = result_1 + result_2 + result_3\n",
        "  final_result = np.round(final_result)\n",
        "  final_result = np.clip(final_result, 0, None)\n",
        "\n",
        "  return final_result"
      ],
      "metadata": {
        "id": "tXFIeTEcNVoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_demand(nr_days, randomness_level, peak_randomness):\n",
        "  \"\"\"\n",
        "    Generates the demand for car sharing service in a german city for a given number\n",
        "    of days, general randomness level and demand's peak specific randomness. It uses the helper \n",
        "    functions defined above and returns a Pandas DataFrame, containing 4 features \n",
        "    'Demand', 'Hour', 'Day of week' and 'Specific hour' (the same as 'Hour' column but it\n",
        "    contains only values from 0 to 23, which are helpful while visualising the data).\n",
        "  \"\"\"\n",
        "\n",
        "  weekdays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
        "\n",
        "  # A numpy array which will contain the hourly demand values.\n",
        "  demand = np.empty((0,))\n",
        "  \n",
        "  # Defining a list of dictionaries for the demand parameters of each day of the week. \n",
        "  # The values are based on the research paper that I should imitate.\n",
        "  days = [\n",
        "          {\n",
        "            \"cos_first_val\": 90, \n",
        "            \"cos_nr_points\": 8, \n",
        "            \"first_peak_val\": 200, \n",
        "            \"first_peak_resp_h\": 12, \n",
        "            \"first_peak_diff_max_min\": 110, \n",
        "            \"second_peak_val\": 280, \n",
        "            \"second_peak_resp_h\": 18, \n",
        "            \"second_peak_diff_max_min\": 150\n",
        "           },\n",
        "          {\n",
        "            \"cos_first_val\": 95, \n",
        "            \"cos_nr_points\": 8, \n",
        "            \"first_peak_val\": 180, \n",
        "            \"first_peak_resp_h\": 12, \n",
        "            \"first_peak_diff_max_min\": 80, \n",
        "            \"second_peak_val\": 240, \n",
        "            \"second_peak_resp_h\": 17,   \n",
        "            \"second_peak_diff_max_min\": 140\n",
        "           },    \n",
        "          {\n",
        "            \"cos_first_val\": 90, \n",
        "            \"cos_nr_points\": 8, \n",
        "            \"first_peak_val\": 150, \n",
        "            \"first_peak_resp_h\": 11, \n",
        "            \"first_peak_diff_max_min\": 50, \n",
        "            \"second_peak_val\": 260, \n",
        "            \"second_peak_resp_h\": 18, \n",
        "            \"second_peak_diff_max_min\": 190\n",
        "           },    \n",
        "          {\n",
        "            \"cos_first_val\": 70, \n",
        "            \"cos_nr_points\": 6, \n",
        "            \"first_peak_val\": 240, \n",
        "            \"first_peak_resp_h\": 8, \n",
        "            \"first_peak_diff_max_min\": 90, \n",
        "            \"second_peak_val\": 300, \n",
        "            \"second_peak_resp_h\": 18, \n",
        "            \"second_peak_diff_max_min\": 210\n",
        "           },    \n",
        "          { \n",
        "            \"cos_first_val\": 50, \n",
        "            \"cos_nr_points\": 6, \n",
        "            \"first_peak_val\": 200, \n",
        "            \"first_peak_resp_h\": 8, \n",
        "            \"first_peak_diff_max_min\": 90, \n",
        "            \"second_peak_val\": 340, \n",
        "            \"second_peak_resp_h\": 16, \n",
        "            \"second_peak_diff_max_min\": 270\n",
        "           },    \n",
        "          {\n",
        "            \"cos_first_val\": 50, \n",
        "            \"cos_nr_points\": 6, \n",
        "            \"first_peak_val\": 240, \n",
        "            \"first_peak_resp_h\": 7, \n",
        "            \"first_peak_diff_max_min\": 100, \n",
        "            \"second_peak_val\": 340, \n",
        "            \"second_peak_resp_h\": 17, \n",
        "            \"second_peak_diff_max_min\": 200\n",
        "           },    \n",
        "          {\n",
        "            \"cos_first_val\": 60, \n",
        "            \"cos_nr_points\": 6, \n",
        "            \"first_peak_val\": 260, \n",
        "            \"first_peak_resp_h\": 8, \n",
        "            \"first_peak_diff_max_min\": 110, \n",
        "            \"second_peak_val\": 410, \n",
        "            \"second_peak_resp_h\": 19, \n",
        "            \"second_peak_diff_max_min\": 310\n",
        "           }\n",
        "          ]\n",
        "\n",
        "  changing_factor = 1\n",
        "\n",
        "  # Iterating for each day\n",
        "  for i in np.arange(nr_days):\n",
        "    day_index = i % 7\n",
        "    day = days[day_index]\n",
        "    cos_first_val = day[\"cos_first_val\"]\n",
        "    cos_nr_points = day[\"cos_nr_points\"]\n",
        "    first_peak_val = day[\"first_peak_val\"]\n",
        "    first_peak_resp_h = day[\"first_peak_resp_h\"]\n",
        "    first_peak_diff_max_min = day[\"first_peak_diff_max_min\"]\n",
        "    second_peak_val = day[\"second_peak_val\"]\n",
        "    second_peak_resp_h = day[\"second_peak_resp_h\"]\n",
        "    second_peak_diff_max_min = day[\"second_peak_diff_max_min\"]\n",
        "\n",
        "    # Storing the function result into 'daily_demand'\n",
        "    daily_demand = generate_daily_demand_updated(cos_first_val, cos_nr_points, first_peak_val, \n",
        "                                  first_peak_resp_h, first_peak_diff_max_min,\n",
        "                                  second_peak_val, second_peak_resp_h, \n",
        "                                  second_peak_diff_max_min, randomness_level,\n",
        "                                  peak_randomness) * changing_factor\n",
        "    \n",
        "    # Extending the current 'demand' numpy array with each 'daily_demand'\n",
        "    demand = np.concatenate((demand, daily_demand), axis=0)\n",
        "\n",
        "    # Increasing/decreasing the demand every week, starting from the second one, using a random factor \n",
        "    if i % 7 == 6:\n",
        "      increase_decrease_demand = np.random.choice(['increase', 'decrease'], p=[0.6, 0.4])\n",
        "      if increase_decrease_demand == 'increase':\n",
        "        changing_factor = np.random.choice([1.1, 1.2, 1.3])\n",
        "      else:\n",
        "        changing_factor = np.random.choice([0.7, 0.8, 0.9])\n",
        "\n",
        "\n",
        "  # Creating a Pandas DataFrame containing 2 columns, \"Hour\" and \"Demand\" \n",
        "  df = pd.DataFrame({'Demand' : demand,\n",
        "                     'Hour' : np.arange(nr_days * 24)})\n",
        "  \n",
        "  # Adding 2 new columns for the respective day of week and the specific hour (0-23)\n",
        "  df['Day of week'] = pd.Series(weekdays)[(df['Hour'] // 24) % 7].values\n",
        "  df['Specific hour'] = df['Hour'] % 24\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "txXTLhi0NXjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df = generate_demand(nr_days = 9, randomness_level = 3, peak_randomness = 4)\n",
        "px.scatter(temp_df, x = 'Hour', y = 'Demand', hover_data = ['Specific hour', 'Day of week'])"
      ],
      "metadata": {
        "id": "9mwqXs0NNY_U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}